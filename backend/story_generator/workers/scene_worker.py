"""
Scene Worker - Worker t·∫°o scenes trong background. 

NHI·ªÜM V·ª§: 
- Nh·∫≠n scenes 2-6 t·ª´ API
- T·∫°o PARALLEL 3 scenes c√πng l√∫c (batch processing)
- Upload l√™n storage
- Update database
- Update progress sau m·ªói batch
"""

import asyncio
import logging
import time
from story_generator.database import Database
from story_generator.services.image_generator import ImageGenerator
from story_generator.services.voice_generator import VoiceGenerator 

logger = logging.getLogger(__name__)


async def generate_single_scene_worker(
    scene_data: dict,
    db_scene: dict,
    request_params: dict,
    character_design: str,
    background_design: str,
    story_id: str,
    image_gen: ImageGenerator,
    voice_gen: VoiceGenerator,
    db: Database
) -> dict:
    """
    T·∫°o M·ªòT scene (image + audio).
    
    D√πng trong worker ƒë·ªÉ process parallel.
    
    Returns:
        dict v·ªõi status ('completed' ho·∫∑c 'failed')
    """
    scene_num = db_scene["scene_order"]
    scene_id = db_scene["id"]
    
    try:
        logger.info(f"   üé® Scene {scene_num} starting...")
        
        #1. Update status = generating
        await db.update_scene_status(scene_id, "generating")
        
        start_time = time.time()
        
        #2. Generate image + audio (parallel)
        image_task = image_gen.generate_image(
            prompt=db_scene["image_prompt_used"],
            style=request_params.get("image_style"),
            scene_number=scene_num,
            character_design=character_design,
            background_design=background_design
        )
        
        audio_task = voice_gen.generate_audio(
            text=db_scene["paragraph_text"],
            voice=request_params.get("voice")
        )
        
        image_bytes, (audio_bytes, audio_duration) = await asyncio.gather(
            image_task,
            audio_task
        )
        
        #3. Upload (parallel)
        image_path = f"{story_id}/scene_{scene_num}.png"
        audio_path = f"{story_id}/scene_{scene_num}.mp3"
        
        image_url, audio_url = await asyncio.gather(
            db.upload_file("story-images", image_path, image_bytes, "image/png"),
            db.upload_file("story-audio", audio_path, audio_bytes, "audio/mpeg")
        )
        
        #4. Update scene database and ƒë√°nh d·∫•u Success
        await db.update_scene(scene_id, {
            "image_url":  image_url,
            "audio_url": audio_url
        })
        
        # Update status = completed
        await db.update_scene_status(scene_id, "completed")
        
        duration = time.time() - start_time
        logger.info(f"   ‚úÖ Scene {scene_num} OK ({duration:.2f}s)")
        
        return {
            "scene_number": scene_num,
            "scene_id": scene_id,
            "status": "completed",
            "duration": duration
        }
        
    except Exception as e:
        logger.error(f"   ‚ùå Scene {scene_num} FAILED: {e}")
        
        # Mark as failed
        await db.update_scene_status(
            scene_id, 
            "failed", 
            error_message=str(e)
        )
        
        return {
            "scene_number":  scene_num,
            "scene_id": scene_id,
            "status": "failed",
            "error":  str(e)
        }


async def generate_remaining_scenes(
    story_id: str,
    scenes_data: list,
    db_scenes: list,
    request_params: dict,
    character_design: str,
    background_design: str,
    image_gen: ImageGenerator,
    voice_gen: VoiceGenerator,
    db: Database
):
    """
    Worker function - T·∫°o scenes 2-6 v·ªõi PARALLEL PROCESSING.
    
    STRATEGY:
    - T·∫°o 3 scenes c√πng l√∫c (batch)
    - Batch 1: scenes 2, 3, 4
    - Batch 2: scenes 5, 6
    
    BENEFITS:
    - Gi·∫£m th·ªùi gian t·ª´ ~30s xu·ªëng ~15s cho 6 scenes
    - T·∫≠n d·ª•ng I/O concurrency
    - API calls song song
    
    Args:
        story_id: ID c·ªßa story
        scenes_data: List data t·ª´ Gemini
        db_scenes: List scene records t·ª´ DB
        request_params: Parameters (image_style, voice)
        character_design: Character description
        background_design: Background description
        image_gen: ImageGenerator instance
        voice_gen: VoiceGenerator instance
        db: Database instance
    """
    
    logger.info(f"üöÄ Worker started: {story_id}")
    logger.info(f"   Strategy:  Parallel batch processing (3 scenes per batch)")
    
    total_scenes = len(db_scenes)
    completed_count = 1  # Scene 1 ƒë√£ xong
    
    try:
        # Skip scene 1 (ƒë√£ t·∫°o trong API 1)
        remaining = list(zip(scenes_data[1:], db_scenes[1:]))
        
        if not remaining:
            logger.warning("‚ö†Ô∏è No remaining scenes to generate")
            return
        
        # ==========================================
        # PARALLEL BATCH PROCESSING
        # ==========================================
        BATCH_SIZE = 5  # T·∫°o 3 scenes c√πng l√∫c
        
        # Chia th√†nh batches
        batches = [
            remaining[i:i + BATCH_SIZE] 
            for i in range(0, len(remaining), BATCH_SIZE)
        ]
        
        logger.info(f"   üì¶ Total batches:   {len(batches)}")
        
        for batch_idx, batch in enumerate(batches, 1):
            batch_size = len(batch)
            scene_numbers = [db_scene["scene_order"] for _, db_scene in batch]
            
            logger.info(f"")
            logger.info(f"üì¶ BATCH {batch_idx}/{len(batches)}: Scenes {scene_numbers}")
            logger.info(f"   Processing {batch_size} scenes in parallel...")
            
            batch_start = time.time()
            
            # ==========================================
            # T·∫†O T·∫§T C·∫¢ SCENES TRONG BATCH SONG SONG
            # ==========================================
            tasks = []
            for scene_data, db_scene in batch: 
                task = generate_single_scene_worker(
                    scene_data=scene_data,
                    db_scene=db_scene,
                    request_params=request_params,
                    character_design=character_design,
                    background_design=background_design,
                    story_id=story_id,
                    image_gen=image_gen,
                    voice_gen=voice_gen,
                    db=db
                )
                tasks.append(task)
            
            # ƒê·ª£i T·∫§T C·∫¢ scenes trong batch ho√†n th√†nh
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            batch_duration = time.time() - batch_start
            
            # ==========================================
            # PROCESS RESULTS
            # ==========================================
            completed_in_batch = 0
            failed_in_batch = 0
            
            for result in results: 
                if isinstance(result, Exception):
                    logger.error(f"   ‚ùå Task exception: {result}")
                    failed_in_batch += 1
                elif result["status"] == "completed":
                    completed_in_batch += 1
                else:
                    failed_in_batch += 1
            
            # Update total completed count
            completed_count += completed_in_batch + failed_in_batch
            
            # ==========================================
            # UPDATE STORY PROGRESS
            # ==========================================
            await db.update_story_progress(story_id, completed_count, total_scenes)
            
            logger.info(f"")
            logger.info(f"‚úÖ BATCH {batch_idx} DONE in {batch_duration:.2f}s")
            logger.info(f"   Completed: {completed_in_batch}/{batch_size}")
            logger.info(f"   Failed: {failed_in_batch}/{batch_size}")
            logger.info(f"   Overall progress: {completed_count}/{total_scenes}")
        
        # ==========================================
        # ALL BATCHES COMPLETED
        # ==========================================
        await db.update_story_status(story_id, "completed")
        
        logger.info(f"")
        logger.info(f"üéâ Story {story_id} FULLY COMPLETED!")
        logger.info(f"   Total scenes: {completed_count}/{total_scenes}")
        
    except Exception as e:
        logger.error(f"‚ùå Worker CRITICAL FAILURE [{story_id}]: {e}", exc_info=True)
        
        # Mark story as failed
        await db.update_story_status(story_id, "failed")
        
        try:
            await db.client. table("stories").update({
                "error_message": str(e)
            }).eq("id", story_id).execute()
        except:
            pass